# PropantCheckChallenge
## Содержание
1. [Описание решения](#overview)
2. [Запуск обучения](#training)
```
Ne_Beite
├── data
│   ├── labels
│   │   └── train.csv
│   │   └── labels_hand_marked.csv
│   └── train
├── models
│   ├── model.pkl
│   ├── counter_model.pkl
├── preprocessed_imgs
│   ├── 901.jpg
│   ├── 902.jpg
│   ├── 903.jpg
├── README
├── train_distributions.py
├── train_counter.py
├── preprocess.py
├── hough.py
├── requirements.txt
└── run.py
```
## Описание решения <a name="overview"></a>
### Первый метод - (Скор: 0.077): 
 С помощью методов из OpenCV мы вырезаем из фотографии внутренний прямоугольник с гранулами проппанта и запускаем cv2.HoughCircles() для поиска окружностей на картинке. Далее высчитываем средний радиус и делим количество пикселей на переднем плане на фото на площадь круга с средним радиусом. Это и будет количеством гранул в ответе. 
 Для подсчёта распределения гранул по ситам строим распределения радиусов найденных окружностей и по ним обучаем Random Forest для предсказания распределения бинов.
### Второй метод - (Скор: 0.076):
Предсказание распределения такое же как и в первом методе, но для подсчета количества гранул теперь мы используем cv2.connectedComponentsWithStats() чтобы найти площади соединённых компонент (соприкасающихся гранул). Идея в том, чтобы научитсья различать площадь отдельно стоящих гранул от площади нескольких прикасающихся. Для этого строим распределение площадей и обучаем модель AdaBoostRegressor для поиска границ площадей одиночных гранул. Далее, зная все площади и количество контуров между найденной левой и правой границей находим  
площадь отдельной гранулы, а потом делим всю занимаемую гранулами площадь на среднюю площадь одной гранулы чтобы найти их итоговое количество.\
Для более точного результата мы вручную разметили несколько изображений и сделали новые путем вырезки старых. Новый файл для обучения - label_hand_marked.csv. Новые изображения заранее находятся в папке preprocessed_imgs.  
Информация о размеченных нами картинках для удобства вынесена в отдельный csv файл only_augmented.csv

## Запуск обучения <a name="training"></a>
Чтобы более точно воспроизвести скор, пожалуйста запускайте на компьютере с ОС Windows  
1. Для установки виртуального окружения и зависимостей:\
```$ python -m venv env```  
```$ source env/bin/activate```  on Linux, ```$ env\Scripts\activate``` on Windows  
```$ pip install -r requirements.txt```  
2. Загрузите фотографии в папку data/train
3. Для запуска процесса обучения и создания модели:\
```(env) $ python run.py```

## Результаты
Модель распределений model.pkl и модель подсчета models/counter_model.pkl  сохранятся в папке models.\
Воспроизведены результаты следующих посылок:\
1. 01.11.2020 17:00, Скор: 0.07615697727491788 - используется model.pkl и counter_model.pkl  
2. 30.10.2020 09:50, Скор: 0.07708607193722809 - используется только model.pkl


